---
title: "DM2: Analyse Discriminante PLS exploratoire"
author: "Kateryna Stetsun"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

L’Analyse Discriminante PLS exploratoire (ADPLS) est une méthode multivariée qui combine les principes de la régression PLS (Partial Least Squares) et de l’analyse discriminante.  
Son objectif est de construire des composantes linéaires des variables explicatives \( X \) maximisant la capacité de discrimination des groupes définis par la variable qualitative \( Y \).

Autrement dit, on cherche à extraire des axes factoriels \( f = X M u \) expliquant à la fois une grande part de la variance de \( X \) (inertie totale) et une forte part de la variance expliquée par les classes de \( Y \).  
Les notations utilisées sont celles du cours :

- \( X \in \mathbb{R}^{n \times p} \) : matrice des variables quantitatives centrées ;  
- \( Y \in \mathbb{R}^{n \times q} \) : matrice d’indicatrices des \( q \) classes (non centrée) ;  
- \( W = \mathrm{diag}(w_i) \) : matrice diagonale des poids individuels ;  
- \( M \) : métrique définie positive sur l’espace des variables ;  
- \( f = X M u \) : composante discriminante associée à la direction \( u \) ;  
- \( \Pi_Y = Y (Y' W Y)^{-1} Y' W \) : projecteur sur l’espace engendré par \( Y \) ;  
- \( \widehat{X} = \Pi_Y X \) : projection de \( X \) sur cet espace.

# Partie 2 — Programmation

Dans cette partie nous implémentons pas à pas l'ADPLS.

Objectifs de la section sont:

- définir les variables d'entrée (X, Y, H, w, M, options) ;  
- construire le projecteur sur l'espace des indicatrices \(Y\) ;  
- calculer les \(H\) premières composantes discriminantes \(f_h = X M u_h\) avec la contrainte \(u'_M u = 1\) et l'orthogonalité par rapport aux composantes précédentes ;  
- stocker les vecteurs propres et les scores normalisés pour usage ultérieur.


## Variables d'entrée et fonctions utilitaires

Données d'entrée

```{r setup_inputs, echo=TRUE}
# X : matrice n x p (variables numériques) — non nécessairement centrée
# Y : matrice n x q d'indicatrices (0/1) des q modalités
# H : nombre de composantes à calculer
# w : vecteur de poids length n (NULL -> poids égaux)
# M : matrice métrique p x p (NULL -> identité)
# center_scale : centrer et réduire X si TRUE

# Exemple :
# X <- as.matrix(X)        # n x p
# Y <- as.matrix(Y)        # n x q
# H <- 3
# w <- rep(1 / nrow(X), nrow(X))
# M <- diag(ncol(X))
# center_scale <- TRUE
```

Fonctions utilitaires pondérées

```{r setup_inputs_1, echo=TRUE}
Wmat <- function(w) {
  if (is.null(w)) return(NULL)
  diag(as.numeric(w), nrow = length(w))
}

# norme pondérée ||v||_W^2 = v' W v
w_norm2 <- function(v, w) {
  if (is.null(w)) return(as.numeric(t(v) %*% v))
  as.numeric(t(v) %*% (w * v))
}

# produit scalaire pondéré <a,b>_W = a' W b
w_prod <- function(a, b, w) {
  if (is.null(w)) return(as.numeric(t(a) %*% b))
  as.numeric(t(a) %*% (w * b))
}

# racine symétrique de M (M supposée SPD ou semi-définie)
M_half <- function(M) {
  ev <- eigen(M, symmetric = TRUE)
  vals <- pmax(ev$values, 0)
  vecs <- ev$vectors
  vecs %*% diag(sqrt(vals), length(vals)) %*% t(vecs)
}

# inverse de la racine (pseudo-inverse si valeurs nulles)
M_half_inv <- function(M) {
  ev <- eigen(M, symmetric = TRUE)
  vals <- ev$values
  vecs <- ev$vectors
  invvals <- ifelse(vals > 0, 1 / sqrt(vals), 0)
  vecs %*% diag(invvals, length(invvals)) %*% t(vecs)
}
```

## 1. Calcul des H premières composantes ADPLS

Par definition nous savons que \( f_h = X M u_h \), où \( u_h\) est le vecteur propre de \( E_h = \hat{X}' W \hat{X} \)  associé à la plus grande valeur propre, projeté orthogonalement aux composantes précédentes.

```{r adpls_part1, echo=TRUE}
adpls_part1 <- function(X, Y, H = 2, w = NULL, M = NULL, center_scale = TRUE) {
  
  # Vérifications et préparation
  X <- as.matrix(X)
  Y <- as.matrix(Y)
  n <- nrow(X)
  p <- ncol(X)
  
  if (nrow(Y) != n) stop("X et Y doivent avoir le même nombre de lignes (individus).")
  if (is.null(w)) w <- rep(1 / n, n)
  w <- as.numeric(w)
  if (length(w) != n) stop("Longueur de w différente de n (nrow(X)).")
  W <- diag(w)
  if (center_scale) X <- scale(X, center = TRUE, scale = TRUE)
  if (is.null(M)) M <- diag(1, p)
  if (!all(dim(M) == c(p, p))) stop("M doit être p x p.")
  
  # Racines de M pour changement de métrique
  sqrtM <- M_half(M)
  inv_sqrtM <- M_half_inv(M)
  
  # Projecteur sur l'espace engendré par Y : PiY = Y (Y' W Y)^{-1} Y' W
  YYw <- t(Y) %*% (W %*% Y)
  inv_YYw <- solve(YYw)
  PiY <- Y %*% inv_YYw %*% t(Y) %*% W
  
  # Projection de X sur l'espace de Y
  Xhat <- PiY %*% X
  
  # Matrice E = Xhat' W Xhat utilisée pour la diagonalisation
  E <- t(Xhat) %*% (W %*% Xhat)
  
  # Réserves pour résultats
  if (is.null(H) || !is.numeric(H) || H < 1) stop("H doit être un entier positif.")
  H <- as.integer(H)
  U_list <- vector("list", H)       # vecteurs u_h (p x 1)
  F <- matrix(0, n, H)              # scores non normalisés
  Ftilde <- matrix(0, n, H)         # scores normalisés (||ftilde||_W = 1)
  
  # Boucle sur h = 1..H
  for (h in seq_len(H)) {
    if (h == 1) {
      # première composante : diagonaliser Estar = sqrtM %*% E %*% sqrtM
      Estar <- sqrtM %*% E %*% sqrtM
      ev <- eigen(Estar, symmetric = TRUE)
      ustar <- ev$vectors[, 1]        # vecteur propre principal en métrique transformée
      u <- inv_sqrtM %*% ustar        # retour dans l'espace u
      # normalisation selon la contrainte u' M u = 1
      unorm <- as.numeric(t(u) %*% (M %*% u))
      if (unorm <= 0) stop("Norme u' M u non strictement positive (h=1).")
      u <- u / sqrt(unorm)
    } else {
      # composantes suivantes : contrainte d'orthogonalité à Fprev
      Fprev <- F[, 1:(h - 1), drop = FALSE]   # n x (h-1)
      # D' = Fprev' W X  -> D = t(D') = X' W Fprev  (p x (h-1))
      Dprime <- t(Fprev) %*% (W %*% X)        # (h-1) x p
      D <- t(Dprime)                          # p x (h-1)
      # Construction du projecteur sur l'orthogonal de D (dans métrique M)
      # Pi_D_perp = I_p - D (D' M D)^{-1} D' M
      inner <- t(D) %*% (M %*% D)             # (h-1) x (h-1)
      inv_inner <- solve(inner)
      PiDperp <- diag(1, p) - D %*% inv_inner %*% t(D) %*% M
      # Matrice à diagonaliser dans l'espace réduit
      Estar_proj <- sqrtM %*% PiDperp %*% E %*% t(PiDperp) %*% sqrtM
      ev <- eigen(Estar_proj, symmetric = TRUE)
      ustar <- ev$vectors[, 1]
      u <- inv_sqrtM %*% ustar
      unorm <- as.numeric(t(u) %*% (M %*% u))
      if (unorm <= 0) stop(paste("Norme u' M u non positive (h=", h, ").", sep = ""))
      u <- u / sqrt(unorm)
    }
    
    # Calcul du score f_h = X M u
    f_h <- X %*% (M %*% u)          # n x 1
    fnorm2 <- as.numeric(t(f_h) %*% (W %*% f_h))
    if (fnorm2 <= 0) stop(paste("Norme de f_h <= 0 (h=", h, ").", sep = ""))
    ftilde_h <- f_h / sqrt(fnorm2)  # normalisation pour que ||ftilde||_W = 1
    
    # Stockage
    U_list[[h]] <- as.numeric(u)
    F[, h] <- as.numeric(f_h)
    Ftilde[, h] <- as.numeric(ftilde_h)
  }
  
  # Conversion de la liste de vecteurs en matrice p x H
  U_mat <- do.call(cbind, U_list)
  colnames(U_mat) <- paste0("u", seq_len(ncol(U_mat)))
  colnames(F) <- paste0("f", seq_len(ncol(F)))
  colnames(Ftilde) <- paste0("f_tilde", seq_len(ncol(Ftilde)))
  
  return(list(U = U_mat, F = F, Ftilde = Ftilde, Xhat = Xhat, E = E, PiY = PiY, M = M, w = w))
}
```

## 2. Calcul des indicateurs \( S(f_h) \) et \( R^2 (f_h, Y) \)

Donc il faut pour chaque composante discriminante \( f_h \), nous voulons évaluer :

\( S(f_h) = \frac{\| f_h \|_W^2}{\operatorname{tr}(X' W X)} \)  et \( R^2(f_h, Y) = \frac{\| \hat{f}_h \|_W^2}{\| f_h \|_W^2} \), où \( \hat{f}_h = \Pi_Y f_h = \Pi_Y X M u_h \) et \( \Pi_Y = Y (Y' W Y)^{-1} Y' W \).

\( S(f_h) \) va mesurer la part d'inertie totale expliquée par la composante \( f_h \) et \( R^2 (f_h, Y) \) va mesurer la part de variance de f_h expliquée par les classes Y.


```{r adpls_part2, echo=TRUE}
adpls_part2 <- function(X, Y, H = 2, w = NULL, M = NULL, center_scale = TRUE) {
  # On commence par réutiliser le calcul de la partie 1 :
  part1 <- adpls_part1(X, Y, H, w, M, center_scale)
  
  # Extraction des éléments nécessaires
  X <- as.matrix(X)
  W <- diag(part1$w)
  M <- part1$M
  F <- part1$F
  U <- part1$U
  Xhat <- part1$Xhat
  E <- part1$E
  
  # Calcul de l'inertie totale : tr(X' W X)
  total_inertia <- sum(diag(t(X) %*% (W %*% X)))
  
  # Initialisation des vecteurs résultats
  S_vec <- numeric(H)
  R2_vec <- numeric(H)
  
  # Boucle sur h
  for (h in seq_len(H)) {
    f_h <- F[, h, drop = FALSE]
    fnorm2 <- as.numeric(t(f_h) %*% (W %*% f_h))
    
    # (1) S(f_h) = ||f_h||_W² / tr(X' W X)
    S_vec[h] <- fnorm2 / total_inertia
    
    # (2) R²(f_h, Y) = ||Pi_Y f_h||_W² / ||f_h||_W²
    fhat_h <- part1$PiY %*% f_h
    top_val <- as.numeric(t(fhat_h) %*% (W %*% fhat_h))
    R2_vec[h] <- top_val / fnorm2
  }
  
  # On ajoute les résultats à la liste déjà créée
  part1$S <- S_vec
  part1$R2 <- R2_vec
  
  # Retourne la structure enrichie (utile pour la suite)
  return(part1)
}
```

Donc notre vecteur `S_vec` contient les parts d'inertie expliquées par chaque axe : plus $ S(f_h) $ est grand, plus la composante f_h contribue à la discrimination globale.

Le vecteur `R2_vec` mesure la qualité de corrélation entre les scores et les classes :

- $ R^2 $ proche de 1 $ \to $ axe fortement discriminant.
- $ R^2 $ faible $ \to $ axe moins pertinent pour séparer les groupes.

## 3. Calcul des coordonnées des centres de gravité des q classes sur les H axes discriminants

Déterminons, pour chaque classe (parmi les q classes), les coordonnées de son centre de gravité dans l’espace des H premières composantes discriminantes.

Soit \( F = [f_1, f_2, \ldots, f_H] \) la matrice des composantes discriminantes.

Chaque individu i a un vecteur de scores \( f_i = (f_{i1}, \ldots, f_{iH}) \).

Si Y est la matrice d’indicateurs de classes (n × q) : \( Y_{ik} = 1 \) si l’individu i appartient à la classe k, 0 sinon.

Alors les coordonnées du centre de gravité de la classe k sur l’axe h s’obtiennent par :

\[
g_{kh} = \frac{ \sum_{i=1}^{n} W_i \, Y_{ik} \, f_{ih} }
              { \sum_{i=1}^{n} W_i \, Y_{ik} }
\]

En notation matricielle :

\[
G = (Y' W Y)^{-1} Y' W F \)
\]

où :
- G est une matrice q × H,
- chaque ligne correspond au centre d’une classe,
- chaque colonne à un axe discriminant.

```{r adpls_part3, echo=TRUE}
adpls_part3 <- function(X, Y, H = 2, w = NULL, M = NULL, center_scale = TRUE) {
  # On récupère la structure enrichie de la partie 2
  part2 <- adpls_part2(X, Y, H, w, M, center_scale)
  
  # Extraction des objets nécessaires
  W <- diag(part2$w)
  F <- part2$F
  Y <- as.matrix(Y)
  
  # Calcul des coordonnées des centres de gravité :
  # G = (Y' W Y)^(-1) Y' W F
  YtWY <- t(Y) %*% W %*% Y
  YtWF <- t(Y) %*% W %*% F
  G <- solve(YtWY, YtWF)
  
  # Attribution des noms de lignes et de colonnes
  rownames(G) <- colnames(Y)
  colnames(G) <- paste0("Axe_", seq_len(H))
  
  # Ajout des résultats à la liste existante
  part2$centers <- G
  
  return(part2)
}
```

Nous obtenons la matrice, qui G contient les centres de gravité pondérés des classes dans le sous-espace défini par les H composantes discriminantes.

Chaque ligne de G correspond à une classe : permet de visualiser les barycentres dans le plan (h, m), ce qui sera utilisé à la question 5 pour la représentation graphique.

L’utilisation du poids W garantit la cohérence avec la métrique employée dans la construction des composantes.

## 4. Calcul des coordonnées des variables de X

Déterminons la contribution et la représentation des variables initiales X sur les H axes discriminants de l’ADPLS.

On cherche à exprimer la corrélation entre chaque variable $X_j$ et chaque composante discriminante $f_h$.

Pour cela, on utilise la formule :

\[
r_{jh} =  \frac{ \langle X_j , f_h \rangle_W }
               { \|X_j\|_W \, \|f_h\|_W }
\]

où :

- \( X_j \) : j-ième variable centrée-réduite de X
- \( f_h \) : h-ième composante discriminante
- \( \langle \cdot , \cdot \rangle_W \) : produit scalaire pondéré
- \( \|\cdot\|_W \) : norme pondérée

En notation matricielle : 

\[ 
C = \text{corr}(X, F) = D_X^{-1} \, (X' W F) \, D_F^{-1} 
\]

où :

- \( D_X \) : matrice diagonale des normes de $X_j$,
- \( D_F \) : matrice diagonale des normes des $f_h$.

```{r adpls_part4, echo=TRUE}
adpls_part4 <- function(X, Y, H = 2, w = NULL, M = NULL, center_scale = TRUE) {
  # On récupère les éléments calculés précédemment
  part3 <- adpls_part3(X, Y, H, w, M, center_scale)
  
  W <- diag(part3$w)
  F <- part3$F
  X <- scale(X, center = TRUE, scale = TRUE)  # On suppose X centré-réduit
  
  n <- nrow(X)
  p <- ncol(X)
  
  # Initialisation matrice de corrélation variable × axe
  C <- matrix(0, nrow = p, ncol = H)
  
  # Calcul des corrélations pondérées entre X_j et f_h
  for (j in 1:p) {
    xj <- X[, j]
    norm_xj <- sqrt(as.numeric(t(xj) %*% (W %*% xj)))
    
    for (h in 1:H) {
      fh <- F[, h]
      norm_fh <- sqrt(as.numeric(t(fh) %*% (W %*% fh)))
      if (norm_xj == 0 || norm_fh == 0) {
        C[j, h] <- 0
      } else {
        C[j, h] <- as.numeric(t(xj) %*% (W %*% fh)) / (norm_xj * norm_fh)
      }
    }
  }
  
  # Attribution des noms
  rownames(C) <- colnames(X)
  colnames(C) <- paste0("Axe_", seq_len(H))
  
  # Stockage des coordonnées dans la liste principale
  part3$var_coords <- C
  
  return(part3)
}
```

La matrice C (de dimension p × H) contient les coordonnées des variables sur les axes discriminants, c’est-à-dire les corrélations entre chaque variable de X et chaque composante f_h.

Ces coordonnées permettent :
- d’interpréter le rôle des variables dans la discrimination ;
- de visualiser le cercle de corrélation ;
- d’évaluer la contribution de chaque variable à chaque axe.

Valeurs proches de 1 ou -1 indiquent une forte corrélation, tandis que des valeurs proches de 0 montrent une faible contribution.

Créons maintenant une fonction générale composée des fonctions écrites dans les questions 1 à 4.

```{r adpls_full}
adpls_full <- function(X, Y, H=2, w=NULL, M=NULL, center_scale=TRUE){
  
Wmat <- function(w) {
  if (is.null(w)) return(NULL)
  diag(as.numeric(w), nrow = length(w))
}

w_norm2 <- function(v, w) {
  if (is.null(w)) return(sum(v^2))
  as.numeric(t(v) %*% (w * v))
}

w_prod <- function(a, b, w) {
  if (is.null(w)) return(as.numeric(t(a) %*% b))
  as.numeric(t(a) %*% (w * b))
}

M_half <- function(M) {
  ev <- eigen(M, symmetric = TRUE)
  vals <- pmax(ev$values, 0)
  vecs <- ev$vectors
  vecs %*% diag(sqrt(vals), length(vals)) %*% t(vecs)
}

M_half_inv <- function(M) {
  ev <- eigen(M, symmetric = TRUE)
  vals <- ev$values
  vecs <- ev$vectors
  invvals <- ifelse(vals > 0, 1 / sqrt(vals), 0)
  vecs %*% diag(invvals, length(invvals)) %*% t(vecs)
}
 
 
 if (is.null(w)) w <- rep(1 / nrow(X), nrow(X))
  # étape 1 : calcul des composantes
  part1 <- adpls_part1(X = X, Y = Y, H = H, w = w, M = M, center_scale = center_scale)
 
  cat("H =", H, " | length =", length(H), "\n")
   
  #W <- diag(part1$w)
#part2 <- adpls_part2(X, Y, part1$F, W, part1$M)
#part3 <- adpls_part3(Y, part1$Ftilde, W)
#part4 <- adpls_part4(X, part1$F, W)
  
  # étape 2 : indicateurs S et R²
  part2 <- adpls_part2(X = X, Y = Y, H = H, w = w, M = M, center_scale = center_scale)
  
  # étape 3 : centres de gravité
  part3 <- adpls_part3(X = X, Y = Y, H = H, w = w, M = M, center_scale = center_scale)
  
  # étape 4 : coordonnées des variables
  part4 <- adpls_part4(X = X, Y = Y, H = H, w = w, M = M, center_scale = center_scale)
  
  # étape 5 : visualisation (optionnelle)
  # plot_adpls(part1, Y=Y, ...)
  
  # combiner tous les résultats
  return(list(F=part1$F, Ftilde=part1$Ftilde,
              S=part2$S, R2=part2$R2,
              centers=part3$centers,
              var_coords=part4$var_coords))
}
```

## 5. Représentation graphique des individus, des centres de gravité et des variables

Dans cette dernière étape, nous devons visualiser les résultats obtenus dans les étapes précédentes.  
L’objectif est triple :

1. Afficher les individus dans le plan factoriel (h, m) choisi par l'utilisateur.
2. Afficher les centres de gravité des q classes sur ce même plan.
3. Afficher les variables de X projetées sur le plan choisi et tracer le cercle unité.

La réponse sera la fonction `plot_adpls()` qui va afficher graphique dans le plan \((h, m)\).

Cette fonction trace :
- les individus colorés selon leur classe ;
- les centres de gravité des q classes ;
- les variables de X projetées sur le plan choisi ;
- et le cercle unité, pour faciliter l'interprétation des corrélations.

```{r plot_adpls, echo=TRUE }
plot_adpls <- function(out, Y = NULL, Y_labels = NULL, h = 1, m = 2,
                       show_variables = TRUE, circle = TRUE,
                       main = NULL, cex_ind = 0.7, cex_cent = 1.0) {

  # coordonnées normalisées des individus
  Ftilde <- out$Ftilde
  # coordonnées des centres de gravité
  centers <- out$centers
  # coordonnées des variables
  var_coords <- out$var_coords
  n <- nrow(Ftilde)
  
  # identification des étiquettes de classes
  if (is.null(Y_labels) & !is.null(Y)) {
    lab <- apply(Y, 1, function(r) which(r == 1))
    Y_labels <- factor(lab)
  } else if (is.null(Y_labels)) {
    stop("Y_labels ou Y doivent être fournis")
  }
  
  # coordonnées des individus sur le plan (h, m)
  xind <- Ftilde[, h]
  yind <- Ftilde[, m]
  classes <- as.factor(Y_labels)
  cols <- rainbow(length(levels(classes)))
  
  # tracé des individus
  plot(xind, yind, col = cols[as.numeric(classes)], pch = 16, cex = cex_ind,
       xlab = paste0("Axe ", h), ylab = paste0("Axe ", m), main = main)
  legend("topright", legend = levels(classes), col = cols, pch = 16, cex = 0.8)
  
  # centres de gravité
  points(centers[, h], centers[, m], col = "black", pch = 8, cex = cex_cent)
  text(centers[, h], centers[, m], labels = rownames(centers), pos = 3)
  
  # variables dans le plan
  if (show_variables) {
    arrows(rep(0, nrow(var_coords)), rep(0, nrow(var_coords)),
           var_coords[, h], var_coords[, m],
           length = 0.07, col = "darkgrey")
    
    text(var_coords[, h], var_coords[, m],
         labels = rownames(var_coords),
         cex = 0.7)
    
    # cercle unité pour corrélations
    if (circle) {
      angles <- seq(0, 2*pi, length.out = 200)
      lines(cos(angles), sin(angles), lty = 2)
    }
  }
}

# opérateur utilitaire : renvoie a si non nul, sinon b
`%||%` <- function(a, b) if (!is.null(a)) a else b
```

## Exemple d'application avec les données `Datagenus` du premier TP :

```{r exemple}

data <- read.table("Datagenus.csv", header = TRUE)
X <- scale(as.matrix(data[, paste0("gen", 1:27)]), center = TRUE, scale = TRUE)
grp <- as.factor(data$forest)
Y <- model.matrix(~ grp - 1)
out <- adpls_full(X, Y, H = 3, w = rep(1 / nrow(X), nrow(X)), M = NULL, center_scale = FALSE)

data.frame(
  Axe = 1:3,
  S = round(out$S, 3),
  R2 = round(out$R2, 3),
  Discriminant = round(out$S * out$R2, 3)
)

plot_adpls(out, Y = Y, Y_labels = grp, h = 1, m = 2, show_variables = TRUE)
```